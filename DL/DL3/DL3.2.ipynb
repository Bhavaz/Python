{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL3.2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9yhS8edAH1yz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":700},"outputId":"ed7dd942-e867-46b1-a6c7-c2d68c65fb7d","executionInfo":{"status":"ok","timestamp":1562880819536,"user_tz":300,"elapsed":204944,"user":{"displayName":"bhavaz Akula","photoUrl":"https://lh6.googleusercontent.com/-s3FsBBt0_YM/AAAAAAAAAAI/AAAAAAAAAGU/r_PahSF1pk0/s64/photo.jpg","userId":"04526873242377407941"}}},"source":["from keras.models import Sequential\n","from keras import layers\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import  Embedding\n","from keras.layers import  Flatten\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","df = pd.read_csv('imdb_master.csv',encoding='latin-1')\n","sentences = df['review'].values\n","y = df['label'].values\n","#tokenizing data\n","tokenizer = Tokenizer(num_words=2000)\n","#tokenizer.fit_on_texts(sentences)\n","#getting the vocabulary of data\n","#sentences = tokenizer.texts_to_matrix(sentences)\n","max_review_len= max([len(s.split()) for s in sentences])\n","vocab_size= len(tokenizer.word_index)+1\n","sentences = tokenizer.texts_to_sequences(sentences)\n","padded_docs= pad_sequences(sentences,maxlen=max_review_len)\n","print(max_review_len)\n","print(vocab_size)\n","\n","le = preprocessing.LabelEncoder()\n","y = le.fit_transform(y)\n","X_train, X_test, y_train, y_test = train_test_split(padded_docs, y, test_size=0.25, random_state=1000)\n","\n","\n","# Number of features\n","# print(input_dim)\n","model = Sequential()\n","input_dim = 2000  #input_dim is input vector i.e 2000\n","model.add(Embedding(vocab_size, 50, input_length=max_review_len))\n","model.add(Flatten())\n","model.add(layers.Dense(300,input_dim=input_dim, activation='relu'))\n","model.add(layers.Dense(2000, activation='softmax'))\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])\n","history=model.fit(X_train,y_train, epochs=10, verbose=True, validation_data=(X_test,y_test), batch_size=256)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2470\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0711 21:30:36.083463 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0711 21:30:36.111494 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0711 21:30:36.115773 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0711 21:30:36.183426 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0711 21:30:36.214315 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0711 21:30:36.344466 140603321948032 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0711 21:30:36.405289 140603321948032 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 75000 samples, validate on 25000 samples\n","Epoch 1/10\n","75000/75000 [==============================] - 35s 472us/step - loss: 1.1062 - acc: 0.4898 - val_loss: 1.0522 - val_acc: 0.5026\n","Epoch 2/10\n","75000/75000 [==============================] - 16s 212us/step - loss: 1.0443 - acc: 0.4991 - val_loss: 1.0424 - val_acc: 0.5026\n","Epoch 3/10\n","75000/75000 [==============================] - 16s 214us/step - loss: 1.0438 - acc: 0.4991 - val_loss: 1.0395 - val_acc: 0.5026\n","Epoch 4/10\n","75000/75000 [==============================] - 16s 217us/step - loss: 1.0432 - acc: 0.4991 - val_loss: 1.0448 - val_acc: 0.5026\n","Epoch 5/10\n","75000/75000 [==============================] - 16s 219us/step - loss: 1.0423 - acc: 0.4991 - val_loss: 1.0410 - val_acc: 0.5026\n","Epoch 6/10\n","75000/75000 [==============================] - 17s 221us/step - loss: 1.0427 - acc: 0.4991 - val_loss: 1.0450 - val_acc: 0.5026\n","Epoch 7/10\n","75000/75000 [==============================] - 17s 220us/step - loss: 1.0442 - acc: 0.4991 - val_loss: 1.0416 - val_acc: 0.5026\n","Epoch 8/10\n","75000/75000 [==============================] - 16s 219us/step - loss: 1.0464 - acc: 0.4949 - val_loss: 1.0385 - val_acc: 0.5026\n","Epoch 9/10\n","75000/75000 [==============================] - 16s 219us/step - loss: 1.0415 - acc: 0.4991 - val_loss: 1.0413 - val_acc: 0.5026\n","Epoch 10/10\n","75000/75000 [==============================] - 16s 219us/step - loss: 1.0414 - acc: 0.4991 - val_loss: 1.0389 - val_acc: 0.5026\n"],"name":"stdout"}]}]}